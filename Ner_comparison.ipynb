{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2a4f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 33: Expected 4 fields in line 33, saw 5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the file\n",
    "df = pd.read_csv(\"NER-test.tsv\", sep=\"\\t\", error_bad_lines=False, engine=\"python\")\n",
    "\n",
    "\n",
    "# Reconstruct sentences and gold tags\n",
    "sentences = defaultdict(list)\n",
    "gold_tags = defaultdict(list)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    sent_id = row['sentence_id']\n",
    "    sentences[sent_id].append(row['token'])\n",
    "    gold_tags[sent_id].append(row['BIO_NER_tag'])\n",
    "\n",
    "tokens_list = list(sentences.values())\n",
    "sent_list = [\" \".join(tokens) for tokens in tokens_list]\n",
    "gold_list = list(gold_tags.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3acdea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp_spacy = spacy.load(\"en_core_web_sm\")\n",
    "spacy_preds = []\n",
    "\n",
    "for tokens in tokens_list:\n",
    "    sentence = \" \".join(tokens)\n",
    "    doc = nlp_spacy(sentence)\n",
    "    ents = [\"O\"] * len(tokens)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        ent_tokens = ent.text.split()\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token in ent_tokens:\n",
    "                prefix = \"B-\" if i == 0 or ents[i-1] == \"O\" else \"I-\"\n",
    "                ents[i] = prefix + ent.label_\n",
    "\n",
    "    spacy_preds.append(ents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4adb968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/poernomo.ah/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6503096c44f40828b6740c4db07b87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31120da9c6364a759cb2a7886b3f2c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cbc7bcf5614eaeb42aef285dd3021d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e64ed0230884bbc9290d3a9991e518e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "hf_ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "hf_preds = []\n",
    "for tokens in tokens_list:\n",
    "    sentence = \" \".join(tokens)\n",
    "    prediction = hf_ner(sentence)\n",
    "    tags = [\"O\"] * len(tokens)\n",
    "\n",
    "    for ent in prediction:\n",
    "        ent_text = ent[\"word\"].split()\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token in ent_text:\n",
    "                prefix = \"B-\" if i == 0 or tags[i-1] == \"O\" else \"I-\"\n",
    "                tags[i] = prefix + ent[\"entity_group\"]\n",
    "\n",
    "    hf_preds.append(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88bbede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== spaCy NER Performance ===\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     PERSON       0.40      0.36      0.38        11\n",
      "WORK_OF_ART       1.00      0.22      0.36         9\n",
      "        LOC       0.00      0.00      0.00         7\n",
      "        ORG       0.00      0.00      0.00         3\n",
      "\n",
      "  micro avg       0.18      0.20      0.19        30\n",
      "  macro avg       0.45      0.20      0.25        30\n",
      "\n",
      "\n",
      "=== HuggingFace NER Performance ===\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     PERSON       0.00      0.00      0.00        11\n",
      "WORK_OF_ART       0.00      0.00      0.00         9\n",
      "        LOC       0.83      0.71      0.77         7\n",
      "        ORG       0.60      1.00      0.75         3\n",
      "\n",
      "  micro avg       0.25      0.27      0.26        30\n",
      "  macro avg       0.25      0.27      0.25        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(\"=== spaCy NER Performance ===\")\n",
    "print(classification_report(gold_list, spacy_preds))\n",
    "\n",
    "print(\"\\n=== HuggingFace NER Performance ===\")\n",
    "print(classification_report(gold_list, hf_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "941b0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "error_df = pd.DataFrame({\n",
    "    \"Sentence\": sent_list,\n",
    "    \"Gold\": gold_list,\n",
    "    \"spaCy\": spacy_preds,\n",
    "    \"HF_BERT\": hf_preds\n",
    "})\n",
    "error_df.to_csv(\"ner_comparison_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3f0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
